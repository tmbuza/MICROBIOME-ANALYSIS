from snakemake.utils import min_version

min_version("6.10.0")

# Configuration file containing all user-specified settings
configfile: "config/config.yaml"

# mothurSamples = list(set(glob_wildcards(os.path.join('data/mothur/reads/', '{sample}_{readNum, R[12]}_001.fastq.gz')).sample))

sraSamples = list(set(glob_wildcards(os.path.join('data/reads/', '{sample}_{sraNum, [12]}.fastq.gz')).sample))

import os
import csv
import pandas as pd

# RUNINFO="data/metadata"
# METADATA=pd.read_csv('OUTDIR/SraRunTable.csv').loc[0:3]
# ACCESSIONS=METADATA['Run'].tolist() # Specify the column containing the accession, in this demo is Run
OUTDIR="data/metadata" 

if not os.path.exists(OUTDIR):
   os.makedirs(OUTDIR)


# Master rule for controlling workflow.
rule all:
    input:
        # expand("data/metadata/runinfo_{bioproject}.csv", bioproject=config["bioproject"]),
        # "data/metadata/runinfo_colnames.csv",
        # "data/metadata/metadata_16S.csv",
        # "data/metadata/metadata_WGS.csv",
        "data/metadata/run_accessions.txt",
        "index.html",

# Download SRA metadata
rule fetch_sra_runinfo:
    output:
        runinfo=expand("data/metadata/runinfo_{bioproject}.csv", bioproject=config["bioproject"]),
    shell:
         "bash workflow/scripts/fetch_sra_runinfo.sh"

        

# Process SRA metadata
rule get_runinfo_columns:
    input:
        rules.fetch_sra_runinfo.output
    output:
        cols="data/metadata/runinfo_colnames.csv",
    script:
        "scripts/get_runinfo_columns.R"
        
# Get Run metadata
rule process_runinfo:
    input:
        runinfo=rules.fetch_sra_runinfo.output.runinfo
    output:
        amp="data/metadata/metadata_16S.csv",
        wgs="data/metadata/metadata_WGS.csv",
    script:
        "scripts/process_runinfo.R"


# Get SRA accessions, the first column of metadata
rule extract_accessions:
    input:
        runinfo=rules.process_runinfo.output
    output:
        runacc="data/metadata/run_accessions.txt",
    script:
        "scripts/get_run_accessions.py"


# # # Process SRA metadata
# # rule get_user_metadata:
# #     output:
# #         metadata="data/metadata/metadata.csv",
# #     script:
# #         "scripts/process_sra_metadata.R"
        

# # # Get variable barplot
# # rule get_variable_freq:
# #     input:
# #         "data/metadata/metadata.csv"
# #     output:
# #         png="images/variable_freq.png",
# #         svg="images/variable_freq.svg"
# #     script:
# #         "scripts/plot_var_freq.R"


# # # Get read size
# # rule explore_read_size:
# #     input:
# #         "data/metadata/metadata.csv"
# #     output:
# #         asce="results/read_size_asce.csv",
# #         desc="results/read_size_desc.csv"
# #     script:
# #         "scripts/explore_read_size.R"
      

# # # Get sample location 
# # rule plot_sample_location:
# #     input:
# #         "data/metadata/metadata.csv"
# #     output:
# #         map="images/sample_gps.png"
# #     script:
# #         "scripts/get_sample_gps.R"





# # # Dowload the SRA RUN reads
# # rule download_sra_reads: 
# #     input:
# #         sra_acc=rules.extract_accessions.output.sra_acc,
# #     output:
# #         "data/reads/{sample}_{sraNum}.fastq",
# #     params:
# #         outdir=OUTDIR,
# #         temp=TEMP,
# #     threads: 1
# #     shell:
# #         """
# #         fasterq-dump \
# #         --split-3 --force \
# #         --skip-technical {wildcards.sample} \
# #         --outdir {params.outdir} \
# #         --temp {params.temp} \
# #         --threads {threads}
# #         """

# # # Subset a test data
# # rule seqkit_subset_fastq:
# #     input:
# #         expand("data/reads/{accession}_1.fastq", accession=ACCESSIONS),
# #         expand("data/reads/{accession}_2.fastq", accession=ACCESSIONS),
# #     output:
# #         "data/test/{accession}_1_sub.fastq",
# #         "data/test/{accession}_2_sub.fastq",
# #     threads: 1
# #     shell:
# #         """
# #         bash workflow/scripts/subset_fastq.sh
# #         """


# # rule seqkit_simple_stats:
# #     input:
# #         script="workflow/scripts/seqkit_stat_1.sh",
# #         rawreads=expand("data/reads/{accession}_{sraNum}.fastq", accession=ACCESSIONS, sraNum=config["sraNum"]),
# #     output:
# #         seqkit1="results/stats1/seqkit_stats.txt",
# #     threads: 1
# #     shell:
# #       "bash {input.script}"


# # rule mothur_mapping_file:
# #     input:
# #         stats1="results/stats1/seqkit_stats.txt"
# #     output:
# #         files="data/metadata/mothur_mapping_file.tsv",
# #     threads: 1
# #     script:
# #       "scripts/mothur_mapping_file.R"


# # rule mothur_design_file:
# #     input:
# #         files="data/metadata/mothur_mapping_file.tsv",
# #     output:
# #         files="data/metadata/mothur_design_file.tsv",
# #     threads: 1
# #     script:
# #       "scripts/mothur_design_file.R"

# # # Downloading and formatting SILVA and RDP reference databases. The v4 region is extracted from 
# # # SILVA database for use as reference alignment.
# # rule mothur_references:
# # 	input:
# # 		script="workflow/scripts/mothurReferences.sh"
# # 	output:
# # 		silvaV4="data/mothur/references/silva.v4.align",
# # 		rdpFasta="data/mothur/references/trainset16_022016.pds.fasta",
# # 		rdpTax="data/mothur/references/trainset16_022016.pds.tax"
# # 	conda:
# # 		"envs/mothur.yaml"
# # 	shell:
# # 		"bash {input.script}"


# # # Downloading the Zymo mock sequence files and extracting v4 region for error estimation.
# # rule mothur_zymo_mock:
# # 	input:
# # 		script="workflow/scripts/mothurMock.sh",
# # 		silvaV4="data/mothur/references/silva.v4.align",
# # 	output:
# # 		mockV4="data/mothur/references/zymo.mock.16S.v4.fasta"
# # 	conda:
# # 		"envs/mothur.yaml"
# # 	shell:
# # 		"bash {input.script}"


# # rule gather_bioinfo_resources:
# #     shell:
# #         """
# #         bash workflow/scripts/get_bioinfo_resources.sh
# #         """


# Get project tree
rule project_tree:
    output:
        tree="images/project_tree.txt"
    shell:
        """
        bash workflow/scripts/tree.sh
        """

# Get smk static report
rule static_snakemake_report:
    output:
        smkhtml="report.html",
        html2png="images/smkreport/screenshot.png"
    shell:
        """
        bash workflow/scripts/smk_html_report.sh
        """

rule deploy_to_github_pages:
    input:
        script="workflow/scripts/render.R",
        rmd="index.Rmd",
        runifo="data/metadata/runinfo_colnames.csv",
        tree="images/project_tree.txt",
        html2png=rules.static_snakemake_report.output.html2png,
    output:
        doc="index.html",
    shell:
        """
        R -e "library(rmarkdown); render('{input.rmd}')"
        """

        # Explore SRA metadata



