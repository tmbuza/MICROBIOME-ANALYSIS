from snakemake.utils import min_version

min_version("6.10.0")


# Configuration file containing all user-specified settings
configfile: "config/config.yaml"


report: "report/workflow.rst"

import os
import csv
import pandas as pd

BIOPROJ=pd.read_csv('data/metadata/metadata.csv').bioproject.unique().tolist()

# Master rule for controlling workflow.
rule all:
    input:
        "index.html",


rule get_bioproj_accessions: 
    output:
        bioproj=BIOPROJ
    shell:
        """
        echo "Getting BioProject accessions"
        """

rule download_bioproj_metadata:
    input:
        bioproj=expand("data/metadata/{bioproject}", bioproject=config["bioproject"]),
    output:
        esearch=expand("data/metadata/{bioproject}_runinfo.csv", bioproject=config["bioproject"]),
        pysradb=expand("data/metadata/{bioproject}_pysradb.csv", bioproject=config["bioproject"]),
    shell:
        "bash workflow/scripts/download_sra_metadata.sh" 


rule process_sra_metadata:  
    input:
        esearch=expand("data/metadata/{bioproject}_runinfo.csv", bioproject=config["bioproject"]),
        pysradb=expand("data/metadata/{bioproject}_pysradb.csv", bioproject=config["bioproject"]),
        metadata=expand("data/metadata/{bioproject}_SraRunTable.csv", bioproject=config["bioproject"]),
    output:
        tidymeta=expand("data/metadata/{bioproject}_tidy_metadata.csv", bioproject=config["bioproject"]),
    script:
        "scripts/process_sraruntable.R" 

# Merged project metadata
rule merge_bioproj_metadata:
    input:
        esearch=expand("data/metadata/{bioproject}_runinfo.csv", bioproject=config["bioproject"]),    
        meta=expand(rules.process_sra_metadata.output, bioproject=config["bioproject"]),
        tidymeta=expand("data/metadata/{bioproject}_tidy_metadata.csv", bioproject=config["bioproject"]),
    output:
        mergedmeta="data/metadata/metadata.csv",
    script:
        "scripts/merge_proj_metadata.R"


rule create_mapping_files:  
    input:
        metadata="data/metadata/metadata.csv"
    output:
        samples="config/samples.tsv",
        units="config/units.tsv",
    script:
        "scripts/samples_units_metadata.R"     
 

# Get read size
rule create_read_size_table:
    input:
        "data/metadata/metadata.csv",
    output:
        asc="results/read_size_asc.csv",
        desc="results/read_size_desc.csv"
    script:
        "scripts/explore_read_size.R"


# Get variable barplot
rule plot_read_size:
    input:
        asc="results/read_size_asc.csv",
        desc="results/read_size_desc.csv"
    output:
        png="images/read_size.png",
        svg=report("images/read_size.svg", caption="report/readsize.rst", category="Read size"),
        varpng="images/PRJNA477349_read_size.png",
        varsvg=report("images/PRJNA477349_read_size.svg", caption="report/var.rst", category="Variable bars"),
    script:
        "scripts/plot_var_freq.R"



# Get sample location 
rule plot_sampling_points:
    input:
        metadata="data/metadata/metadata.csv",
    output:
        gps=report("images/sample_gps.png", caption="report/gps.rst", category="Sampling GPS"),
    script:
        "scripts/plot_sampling_points.R"


# Get dot rule graphs
rule dot_rules_graph:
	output:
		"dags/rulegraph.svg",
		"dags/rulegraph.png",
	shell:
		"bash workflow/scripts/rules_dag.sh"


# Get project tree
rule project_tree:
    output:
        tree="results/project_tree.txt"
    shell:
        """
        bash workflow/scripts/tree.sh
        """

# Get smk static report
rule static_smk_report:
    output:
        smkhtml="report.html",
        html2png="images/smkreport/screenshot.png"
    shell:
        """
        bash workflow/scripts/smk_html_report.sh
        """

# rule create_read_size_report:
#     input:
#         sizeasc="results/read_size_asc.csv",
#         sizedecs="results/read_size_desc.csv",
#     output:
#         html="reports/analysis_report.html"
#     run:
#         from snakemake.utils import report
#         import os
#         import sys
#         import csv
#         import pandas as pd

#         report(
#             """
#             Project run with smallest read size (see T1) and highest run read size (see T2)
#             """, 
#             output[0], T1=input[0], T2=input[1])


rule deploy_to_github_pages:
    input:
        script="workflow/scripts/render.R",
        rmd="index.Rmd",
        tree="results/project_tree.txt",
        runselector="images/sra_run_selector.png",
        html2png="images/smkreport/screenshot.png",
        readsize="images/read_size.svg",
        samgps="images/sample_gps.png",
        rules="dags/rulegraph.svg",
        # asc="results/read_size_asc.csv",
        # desc="results/read_size_desc.csv",
    output:
        doc="index.html",
    shell:
        """
        R -e "library(rmarkdown); render('{input.rmd}')"
        """


# snakemake --report report.html
# snakemake --report report.html --report-stylesheet custom-stylesheet.css
# snakemake fig1.svg --report report-short.html
# report: "report/workflow.rst"


# rule all:
#     input:
#         ["fig1.svg", "fig2.png", "testdir"]


# rule c:
#     output:
#         "test.{i}.out"
#     singularity:
#         "docker://continuumio/miniconda3:4.4.10"
#     conda:
#         "envs/test.yaml"
#     shell:
#         "sleep `shuf -i 1-3 -n 1`; touch {output}"


# rule a:
#     input:
#         expand("test.{i}.out", i=range(10))
#     output:
#         report("fig1.svg", caption="report/fig1.rst", category="Step 1")
#     shell:
#         "sleep `shuf -i 1-3 -n 1`; cp data/fig1.svg {output}"


# rule b:
#     input:
#         expand("{model}.{i}.out", i=range(10))
#     output:
#         report("fig2.png", caption="report/fig2.rst", category="Step 2", subcategory="{model}")
#     shell:
#         "sleep `shuf -i 1-3 -n 1`; cp data/fig2.png {output}"

# rule d:
#     output:
#         report(
#             directory("testdir"),
#             patterns=["{name}.txt"],
#             caption="report/somedata.rst",
#             category="Step 3")
#     shell:
#         "mkdir {output}; for i in 1 2 3; do echo $i > {output}/$i.txt; done"