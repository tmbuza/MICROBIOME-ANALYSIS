from snakemake.utils import min_version

min_version("6.10.0")

# Configuration file containing all user-specified settings
configfile: "config/config.yaml"

# Master rule for controlling workflow.
rule all:
    input:
        "config/samples.tsv",
        "config/units.tsv",
        "reports/smk_report.html",
        "reports/analysis_report.html",
        "index.html",

rule download_sra_metadata:  
    output:
        entresefetch=expand("data/metadata/{bioproject}_runinfo.csv", bioproject=config["bioproject"]),
        pysradb=expand("data/metadata/{bioproject}_pysradb.csv", bioproject=config["bioproject"]),
    shell:
        "bash workflow/scripts/download_sra_metadata.sh" 


rule process_sra_metadata:  
    input:
        esearch=expand("data/metadata/{bioproject}_runinfo.csv", bioproject=config["bioproject"]),
        pysradb=expand("data/metadata/{bioproject}_pysradb.csv", bioproject=config["bioproject"]),
        metadata=expand("data/metadata/{bioproject}_SraRunTable.csv", bioproject=config["bioproject"]),
    output:
        tidymeta=expand("data/metadata/{bioproject}_tidy_metadata.csv", bioproject=config["bioproject"]),
    script:
        "scripts/process_sraruntable.R" 

# Merged project metadata
rule merge_proj_metadata:
    input:
        meta=expand(rules.process_sra_metadata.output, bioproject=config["bioproject"]),
        tidymeta=expand("data/metadata/{bioproject}_tidy_metadata.csv", bioproject=config["bioproject"]),
    output:
        mergedmeta="data/metadata/metadata.csv",
    script:
        "scripts/merge_proj_metadata.R"


rule create_mapping_files:  
    input:
        metadata="data/metadata/metadata.csv"
    output:
        samples="config/samples.tsv",
        units="config/units.tsv",
    script:
        "scripts/samples_units_metadata.R"     
 

# Get read size
rule create_read_size_table:
    input:
        "data/metadata/metadata.csv",
    output:
        asc="results/read_size_asc.csv",
        desc="results/read_size_desc.csv"
    script:
        "scripts/explore_read_size.R"


# Get variable barplot
rule plot_read_size:
    input:
        asc="results/read_size_asc.csv",
        desc="results/read_size_desc.csv"
    output:
        svg="images/read_size.svg",
        png="images/read_size.png",
    script:
        "scripts/plot_var_freq.R"



# Get sample location 
rule plot_sampling_points:
    input:
        metadata="data/metadata/metadata.csv",
    output:
        gps="images/sample_gps.png"
    script:
        "scripts/plot_sampling_points.R"


# Get dot rule graphs
rule dot_rules_graph:
	output:
		"dags/rulegraph.svg",
		"dags/rulegraph.png",
	shell:
		"bash workflow/scripts/rules_dag.sh"


# Get project tree
rule project_tree:
    output:
        tree="results/project_tree.txt"
    shell:
        """
        bash workflow/scripts/tree.sh
        """

# Get smk static report
rule static_smk_report:
    output:
        smkhtml="report.html",
        html2png="images/smkreport/screenshot.png"
    shell:
        """
        bash workflow/scripts/smk_html_report.sh
        """

rule create_read_size_report:
    input:
        sizeasc="results/read_size_asc.csv",
        sizedecs="results/read_size_desc.csv",
        svg="images/read_size.svg",
        png="images/read_size.png",
    output:
        html="reports/analysis_report.html"
    run:
        from snakemake.utils import report
        import os
        import sys
        import csv
        import pandas as pd

        report(
            """
            Project run with smallest read size (see T1) and highest run read size (see T2)
            """, 
            output[0], T1=input[0], T2=input[1])


rule get_jobs_runtime_report:
    output:
        "reports/smk_report.html",
    shell:
        "bash workflow/scripts/smk_job_runtime.json"



rule deploy_to_github_pages:
    input:
        script="workflow/scripts/render.R",
        rmd="index.Rmd",
        tree="results/project_tree.txt",
        runselector="images/sra_run_selector.png",
        html2png="images/smkreport/screenshot.png",
        readsize="images/read_size.svg",
        samgps="images/sample_gps.png",
        rules="dags/rulegraph.svg",
        # asc="results/read_size_asc.csv",
        # desc="results/read_size_desc.csv",
    output:
        doc="index.html",
    shell:
        """
        R -e "library(rmarkdown); render('{input.rmd}')"
        """


# snakemake --report report.html
# snakemake --report report.html --report-stylesheet custom-stylesheet.css
# snakemake fig1.svg --report report-short.html
# report: "report/workflow.rst"


# rule all:
#     input:
#         ["fig1.svg", "fig2.png", "testdir"]


# rule c:
#     output:
#         "test.{i}.out"
#     singularity:
#         "docker://continuumio/miniconda3:4.4.10"
#     conda:
#         "envs/test.yaml"
#     shell:
#         "sleep `shuf -i 1-3 -n 1`; touch {output}"


# rule a:
#     input:
#         expand("test.{i}.out", i=range(10))
#     output:
#         report("fig1.svg", caption="report/fig1.rst", category="Step 1")
#     shell:
#         "sleep `shuf -i 1-3 -n 1`; cp data/fig1.svg {output}"


# rule b:
#     input:
#         expand("{model}.{i}.out", i=range(10))
#     output:
#         report("fig2.png", caption="report/fig2.rst", category="Step 2", subcategory="{model}")
#     shell:
#         "sleep `shuf -i 1-3 -n 1`; cp data/fig2.png {output}"

# rule d:
#     output:
#         report(
#             directory("testdir"),
#             patterns=["{name}.txt"],
#             caption="report/somedata.rst",
#             category="Step 3")
#     shell:
#         "mkdir {output}; for i in 1 2 3; do echo $i > {output}/$i.txt; done"